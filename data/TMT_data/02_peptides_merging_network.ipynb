{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/yuliya/repos/cosybio/FedProt/evaluation_utils/')\n",
    "\n",
    "import pandas as pd\n",
    "from preprocessing_MQ import razor_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center1 done\n",
      "Number of peptides: 5958\n",
      "Center2 done\n",
      "Number of peptides: 6303\n",
      "Center3 done\n",
      "Number of peptides: 5528\n"
     ]
    }
   ],
   "source": [
    "# # # CLIENT LEVEL\n",
    "# path_to_data = '/home/yuliya/repos/cosybio/FedProt/data/TMT_data/balanced_data/04_Peptides_PG'\n",
    "# feature_column = 'Proteins'\n",
    "\n",
    "# path_to_data = '/home/yuliya/repos/cosybio/FedProt/data/TMT_data/balanced_data/03_Peptides_Genes'\n",
    "# feature_column = 'Gene.names'\n",
    "\n",
    "# filter_rev check \n",
    "# path_to_data = '/home/yuliya/repos/cosybio/FedProt/data/TMT_data/mapping_filtering_check/custom_NR/'\n",
    "# feature_column = 'Proteins'\n",
    "\n",
    "centers = ['Center1', 'Center2', 'Center3']\n",
    "\n",
    "intensities = {}\n",
    "mappings = {}\n",
    "\n",
    "for center in centers:\n",
    "    aggregated_report = pd.read_csv(f'{path_to_data}/{center}/aggregated_NF.tsv', sep='\\t')\n",
    "    # add all to intensities dict with key = center\n",
    "    intensities[center] = aggregated_report\n",
    "    # add all to mappings dict with key = center\n",
    "    mapping = aggregated_report[['Sequence', feature_column]]\n",
    "    mappings[center] = mapping\n",
    "    print(f'{center} done')\n",
    "    print(f'Number of peptides: {len(aggregated_report)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of peptides in merged mapping: 8824\n",
      "Number of peptides in merged mapping without NAs: 8824\n"
     ]
    }
   ],
   "source": [
    "# SERCER side --- merge mappings from different centers\n",
    "\n",
    "merged_mapping = None\n",
    "\n",
    "for name, df in mappings.items():\n",
    "    if merged_mapping is None:\n",
    "        merged_mapping = df\n",
    "    else:\n",
    "        merged_mapping = pd.merge(merged_mapping, df, on=['Sequence', feature_column], how='outer')\n",
    "\n",
    "print(f'Number of peptides in merged mapping: {len(merged_mapping)}')\n",
    "# remove rows with NA\n",
    "merged_mapping = merged_mapping.dropna(subset=['Sequence', feature_column])\n",
    "print(f'Number of peptides in merged mapping without NAs: {len(merged_mapping)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique peptides: 7793\n"
     ]
    }
   ],
   "source": [
    "def find_union(group, feature_column='Proteins'):\n",
    "    # Find the intersection of lists in \"Gene.names\" within the group\n",
    "    union = set(group[feature_column].iloc[0])\n",
    "    for names in group[feature_column]:\n",
    "        union |= set(names)\n",
    "    # Return a Series with \"Sequences\" and the intersection of \"Gene.names\"\n",
    "    return pd.Series({\n",
    "        feature_column: ';'.join(union)\n",
    "        # 'Gene.names': intersection\n",
    "    })\n",
    "\n",
    "\n",
    "merged_mapping[feature_column] = merged_mapping[feature_column].str.split(';')\n",
    "merged_mapping = merged_mapping.groupby('Sequence').apply(lambda x: find_union(x, feature_column)).reset_index()\n",
    "\n",
    "print(f'Number of unique peptides: {len(merged_mapping)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### server side --- calculate unique and razor\n",
    "final_protein_groups = razor_unique.peptide_grouping(merged_mapping, feature_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 4)\n",
      "(7793, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>peptides</th>\n",
       "      <th>razor_feature</th>\n",
       "      <th>major_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P05154;G3V2M1;G3V264;G3V482;G3V265;G3V3F5;G3V5...</td>\n",
       "      <td>AAAATGTIFTFR</td>\n",
       "      <td>P05154</td>\n",
       "      <td>P05154;G3V2M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P05154;G3V2M1;G3V264;G3V482;G3V265;G3V3F5;G3V5...</td>\n",
       "      <td>AKWETSFNHK</td>\n",
       "      <td>P05154</td>\n",
       "      <td>P05154;G3V2M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P05154;G3V2M1;G3V264;G3V482;G3V265;G3V3F5;G3V5...</td>\n",
       "      <td>AVVEVDESGTR</td>\n",
       "      <td>P05154</td>\n",
       "      <td>P05154;G3V2M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P05154;G3V2M1;G3V264;G3V482;G3V265;G3V3F5;G3V5...</td>\n",
       "      <td>DFTFDLYR</td>\n",
       "      <td>P05154</td>\n",
       "      <td>P05154;G3V2M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P05154;G3V2M1;G3V264;G3V482;G3V265;G3V3F5;G3V5...</td>\n",
       "      <td>EDQYHYLLDR</td>\n",
       "      <td>P05154</td>\n",
       "      <td>P05154;G3V2M1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features      peptides  \\\n",
       "0  P05154;G3V2M1;G3V264;G3V482;G3V265;G3V3F5;G3V5...  AAAATGTIFTFR   \n",
       "0  P05154;G3V2M1;G3V264;G3V482;G3V265;G3V3F5;G3V5...    AKWETSFNHK   \n",
       "0  P05154;G3V2M1;G3V264;G3V482;G3V265;G3V3F5;G3V5...   AVVEVDESGTR   \n",
       "0  P05154;G3V2M1;G3V264;G3V482;G3V265;G3V3F5;G3V5...      DFTFDLYR   \n",
       "0  P05154;G3V2M1;G3V264;G3V482;G3V265;G3V3F5;G3V5...    EDQYHYLLDR   \n",
       "\n",
       "  razor_feature major_features  \n",
       "0        P05154  P05154;G3V2M1  \n",
       "0        P05154  P05154;G3V2M1  \n",
       "0        P05154  P05154;G3V2M1  \n",
       "0        P05154  P05154;G3V2M1  \n",
       "0        P05154  P05154;G3V2M1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_protein_groups_df = pd.DataFrame(final_protein_groups)\n",
    "final_protein_groups_df['major_features'] = final_protein_groups_df['major_features'].apply(lambda x: ';'.join(x))\n",
    "final_protein_groups_df['features'] = final_protein_groups_df['features'].apply(lambda x: ';'.join(x))\n",
    "print(final_protein_groups_df.shape)\n",
    "\n",
    "# split peptides to different rows \n",
    "final_matching = final_protein_groups_df.reset_index(drop=True).explode('peptides')\n",
    "\n",
    "print(final_matching.shape)\n",
    "final_matching.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for center in centers:\n",
    "    # write to file\n",
    "    final_matching.to_csv(f'{path_to_data}/{center}/mapping.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggragate peptides to PG / Genes using mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for center in centers:\n",
    "    aggregated_report = pd.read_csv(f'{path_to_data}/{center}aggregated_NF.tsv', sep='\\t')\n",
    "    final_matching = pd.read_csv(f'{path_to_data}/{center}mapping.tsv', sep='\\t')\n",
    "\n",
    "    ################################  MERGE MAPPING WITH AGGREGATED REPORT  ################################\n",
    "    # rename peptides to Sequence\n",
    "    final_matching = final_matching.rename(columns={'peptides': 'Sequence'})\n",
    "    # merge final_matching with aggregated_report (left join) using 'Sequence' as a key\n",
    "    aggregated_report = pd.merge(aggregated_report, final_matching, on='Sequence', how='left')\n",
    "    # write to file\n",
    "    aggregated_report.to_csv(f'{path_to_data}/{center}/aggregated_NF_mapped.tsv', sep='\\t', index=False)\n",
    "    # remove unnecessary columns\n",
    "    intensities[center] = aggregated_report.drop(columns=['Sequence', 'Proteins', 'Gene.names', 'features', 'razor_feature'])\n",
    "    # drop column where major_features is NA\n",
    "    intensities[center].dropna(subset=['major_features'], inplace=True)\n",
    "\n",
    "    ################################  CHECK FOR CONTAMINANTS  ################################\n",
    "    # Check for contaminants\n",
    "    #  group by major_features and sum intensities for each group (if there is NA in any column, it will be ignored)\n",
    "    reverse_contaminants = intensities[center].groupby('major_features').agg({**{col: 'sum' for col in intensities[center].columns if 'intensity' in col},\n",
    "                                            'Reverse': lambda x: (x == '+').sum(),\n",
    "                                            'Potential.contaminant': lambda x: (x == '+').sum(),\n",
    "                                            'major_features': 'size'})\n",
    "\n",
    "    reverse_contaminants['Reverse_mark'] = reverse_contaminants.apply(lambda x: '+' if x['Reverse'] > x['major_features'] / 2 else 'NA', axis=1)\n",
    "    reverse_contaminants['Potential.contaminant_mark'] = reverse_contaminants.apply(lambda x: '+' if x['Potential.contaminant'] > x['major_features'] / 2 else 'NA', axis=1)\n",
    "    # rename major_features to unique  + razor peptide\n",
    "    reverse_contaminants = reverse_contaminants.rename(columns={'major_features': 'unique_razor_counts'})\n",
    "    reverse_contaminants.drop(columns=['Reverse', 'Potential.contaminant'], inplace=True)\n",
    "\n",
    "    ################################  CALCULATE INTENSITIES  ################################\n",
    "    # Group by major_features and sum intensities for each group\n",
    "    intensities[center].drop(columns=['Reverse', 'Potential.contaminant'], inplace=True)\n",
    "    intensities[center] = intensities[center].groupby('major_features').sum().reset_index()\n",
    "\n",
    "    ################################  WRITE TO FILE  ################################    # write to file\n",
    "    intensities[center].to_csv(f'{path_to_data}/{center}/intensities_counts_ALL.tsv', sep='\\t', index=False)\n",
    "\n",
    "    # filter out contaminants and reverse hit\n",
    "    intensities[center] = pd.merge(intensities[center], reverse_contaminants, on='major_features', how='left')\n",
    "    intensities[center] = intensities[center][intensities[center]['Reverse_mark'] != '+']\n",
    "    intensities[center] = intensities[center][intensities[center]['Potential.contaminant_mark'] != '+']\n",
    "    intensities[center].drop(columns=['Reverse_mark', 'Potential.contaminant_mark'], inplace=True)\n",
    "\n",
    "    # save only intensities to file (without unique_razor_counts column)\n",
    "    intensities[center].drop(columns=['unique_razor_counts']).to_csv(f'{path_to_data}/{center}/intensities_filtered.tsv', sep='\\t', index=False)\n",
    "    # save only unique_razor_counts to file\n",
    "    # intensities[center][['major_features', 'unique_razor_counts']].to_csv(f'{path_to_data}/{center}/counts_filtered_withinCenter.tsv', sep='\\t', index=False)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check on Center 2 values only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center2 done\n",
      "Number of peptides: 6303\n",
      "Number of peptides in merged mapping without NAs: 6143\n"
     ]
    }
   ],
   "source": [
    "# # CLIENT LEVEL\n",
    "# path_to_data = '/home/yuliya/repos/cosybio/FedProt/data/TMT_data/balanced_data/04_Peptides_PG'\n",
    "# output = '/home/yuliya/repos/cosybio/FedProt/data/TMT_data/balanced_data/Check_center_2'\n",
    "# feature_column = 'Proteins'\n",
    "\n",
    "path_to_data = '/home/yuliya/repos/cosybio/FedProt/data/TMT_data/balanced_data/03_Peptides_Genes'\n",
    "output = '/home/yuliya/repos/cosybio/FedProt/data/TMT_data/balanced_data/Check_center_2'\n",
    "feature_column = 'Gene.names'\n",
    "\n",
    "center = 'Center2'\n",
    "\n",
    "aggregated_report = pd.read_csv(f'{path_to_data}/{center}/aggregated_NF.tsv', sep='\\t')\n",
    "# add all to intensities dict with key = center\n",
    "aggregated_report = aggregated_report\n",
    "# add all to mappings dict with key = center\n",
    "mapping = aggregated_report[['Sequence', feature_column]]\n",
    "merged_mapping = mapping\n",
    "print(f'{center} done')\n",
    "print(f'Number of peptides: {len(aggregated_report)}')\n",
    "# remove rows with NA\n",
    "merged_mapping = merged_mapping.dropna(subset=['Sequence', feature_column])\n",
    "print(f'Number of peptides in merged mapping without NAs: {len(merged_mapping)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### server side --- calculate unique and razor\n",
    "final_protein_groups = razor_unique.peptide_grouping(merged_mapping, feature_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(526, 4)\n",
      "(6143, 4)\n",
      "Number of proteins in grouped data: 526\n"
     ]
    }
   ],
   "source": [
    "final_protein_groups_df = pd.DataFrame(final_protein_groups)\n",
    "final_protein_groups_df['major_features'] = final_protein_groups_df['major_features'].apply(lambda x: ';'.join(x))\n",
    "final_protein_groups_df['features'] = final_protein_groups_df['features'].apply(lambda x: ';'.join(x))\n",
    "print(final_protein_groups_df.shape)\n",
    "# split peptides to different rows \n",
    "final_matching = final_protein_groups_df.reset_index(drop=True).explode('peptides')\n",
    "print(final_matching.shape)\n",
    "final_matching.head()\n",
    "print(f\"Number of proteins in grouped data: {len(set(final_matching['major_features'].drop_duplicates().values))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_matching.to_csv(f'{output}/mapping.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique peptides: 501\n"
     ]
    }
   ],
   "source": [
    "aggregated_report = pd.read_csv(f'{path_to_data}/{center}/aggregated_NF.tsv', sep='\\t')\n",
    "final_matching = pd.read_csv(f'{output}/mapping.tsv', sep='\\t')\n",
    "\n",
    "################################  MERGE MAPPING WITH AGGREGATED REPORT  ################################\n",
    "# rename peptides to Sequence\n",
    "final_matching = final_matching.rename(columns={'peptides': 'Sequence'})\n",
    "# merge final_matching with aggregated_report (left join) using 'Sequence' as a key\n",
    "aggregated_report = pd.merge(aggregated_report, final_matching, on='Sequence', how='left')\n",
    "# write to file\n",
    "aggregated_report.to_csv(f'{output}/aggregated_NF_mapped{feature_column}.tsv', sep='\\t', index=False)\n",
    "# remove unnecessary columns\n",
    "aggregated_report = aggregated_report.drop(columns=['Sequence', 'Proteins', 'Gene.names', 'features', 'razor_feature'])\n",
    "# drop column where major_features is NA\n",
    "aggregated_report.dropna(subset=['major_features'], inplace=True)\n",
    "\n",
    "################################  CHECK FOR CONTAMINANTS  ################################\n",
    "# Check for contaminants\n",
    "#  group by major_features and sum intensities for each group (if there is NA in any column, it will be ignored)\n",
    "reverse_contaminants = aggregated_report.groupby('major_features').agg({**{col: 'sum' for col in aggregated_report.columns if 'intensity' in col},\n",
    "                                        'Reverse': lambda x: (x == '+').sum(),\n",
    "                                        'Potential.contaminant': lambda x: (x == '+').sum(),\n",
    "                                        'major_features': 'size'})\n",
    "\n",
    "reverse_contaminants['Reverse_mark'] = reverse_contaminants.apply(lambda x: '+' if x['Reverse'] >= x['major_features'] / 2 else 'NA', axis=1)\n",
    "reverse_contaminants['Potential.contaminant_mark'] = reverse_contaminants.apply(lambda x: '+' if x['Potential.contaminant'] >= x['major_features'] / 2 else 'NA', axis=1)\n",
    "# rename major_features to unique  + razor peptide\n",
    "reverse_contaminants = reverse_contaminants.rename(columns={'major_features': 'unique_razor_counts'})\n",
    "reverse_contaminants.drop(columns=['Reverse', 'Potential.contaminant'], inplace=True)\n",
    "\n",
    "################################  CALCULATE INTENSITIES  ################################\n",
    "# Group by major_features and sum intensities for each group\n",
    "aggregated_report.drop(columns=['Reverse', 'Potential.contaminant'], inplace=True)\n",
    "aggregated_report = aggregated_report.groupby('major_features').sum().reset_index()\n",
    "aggregated_report = pd.merge(aggregated_report, reverse_contaminants, on='major_features', how='left')\n",
    "\n",
    "################################  WRITE TO FILE  ################################\n",
    "# write to file\n",
    "aggregated_report.to_csv(f'{output}/intensities_counts_ALL_pep_to{feature_column}.tsv', sep='\\t', index=False)\n",
    "\n",
    "# filter out contaminants and reverse hits\n",
    "aggregated_report = aggregated_report[aggregated_report['Reverse_mark'] != '+']\n",
    "aggregated_report = aggregated_report[aggregated_report['Potential.contaminant_mark'] != '+']\n",
    "aggregated_report.drop(columns=['Reverse_mark', 'Potential.contaminant_mark'], inplace=True)\n",
    "\n",
    "# save only intensities to file (without unique_razor_counts column)\n",
    "aggregated_report.drop(columns=['unique_razor_counts']).to_csv(f'{output}/intensities_filtered_pep_to{feature_column}.tsv', sep='\\t', index=False)\n",
    "print(f'Number of unique peptides: {len(aggregated_report)}')\n",
    "# save only unique_razor_counts to file\n",
    "aggregated_report[['major_features', 'unique_razor_counts']].to_csv(f'{output}/counts_filtered_pep_to{feature_column}.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedprot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
