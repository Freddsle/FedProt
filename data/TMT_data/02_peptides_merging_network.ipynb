{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center3 done\n",
      "Number of peptides: 5528\n",
      "Center2 done\n",
      "Number of peptides: 6303\n",
      "Center3 done\n",
      "Number of peptides: 5528\n"
     ]
    }
   ],
   "source": [
    "# CLIENT LEVEL\n",
    "path_to_data = '/home/yuliya/repos/cosybio/FedProt/data/TMT_data/balanced_data/04_Peptides_PG'\n",
    "centers = ['Center3', 'Center2', 'Center3']\n",
    "\n",
    "intensities = {}\n",
    "mappings = {}\n",
    "\n",
    "feature = 'Proteins'\n",
    "# featiure = 'Gene.names'\n",
    "\n",
    "for center in centers:\n",
    "    aggregated_report = pd.read_csv(f'{path_to_data}/{center}/aggregated_NF.tsv', sep='\\t')\n",
    "    # add all to intensities dict with key = center\n",
    "    intensities[center] = aggregated_report\n",
    "    # add all to mappings dict with key = center\n",
    "    mapping = aggregated_report[['Sequence', feature]]\n",
    "    mappings[center] = mapping\n",
    "    print(f'{center} done')\n",
    "    print(f'Number of peptides: {len(aggregated_report)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of peptides in merged mapping: 7162\n",
      "Number of peptides in merged mapping without NAs: 7162\n"
     ]
    }
   ],
   "source": [
    "# SERCER side --- merge mappings from different centers\n",
    "\n",
    "merged_mapping = None\n",
    "\n",
    "for name, df in mappings.items():\n",
    "    if merged_mapping is None:\n",
    "        merged_mapping = df\n",
    "    else:\n",
    "        merged_mapping = pd.merge(merged_mapping, df, on=['Sequence', feature], how='outer')\n",
    "\n",
    "print(f'Number of peptides in merged mapping: {len(merged_mapping)}')\n",
    "# remove rows with NA\n",
    "merged_mapping = merged_mapping.dropna(subset=['Sequence', feature])\n",
    "print(f'Number of peptides in merged mapping without NAs: {len(merged_mapping)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique peptides: 7022\n"
     ]
    }
   ],
   "source": [
    "def find_union(group, feature='Proteins'):\n",
    "    # Find the intersection of lists in \"Gene.names\" within the group\n",
    "    union = set(group[feature].iloc[0])\n",
    "    for names in group[feature]:\n",
    "        union |= set(names)\n",
    "    # Return a Series with \"Sequences\" and the intersection of \"Gene.names\"\n",
    "    return pd.Series({\n",
    "        feature: ';'.join(union)\n",
    "        # 'Gene.names': intersection\n",
    "    })\n",
    "\n",
    "\n",
    "merged_mapping[feature] = merged_mapping[feature].str.split(';')\n",
    "merged_mapping = merged_mapping.groupby('Sequence').apply(lambda x: find_union(x, feature)).reset_index()\n",
    "\n",
    "print(f'Number of unique peptides: {len(merged_mapping)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "### server side --- calculate unique and razor\n",
    "\n",
    "df_exploded = merged_mapping.assign(**{feature: merged_mapping[feature].str.split(';')}).explode(feature)\n",
    "\n",
    "unique_razor = df_exploded[feature].value_counts().rename_axis(feature).reset_index(name='Unique_razor')\n",
    "unique_counts = merged_mapping[merged_mapping[feature].str.contains(';') == False][feature].value_counts().rename_axis(feature).reset_index(name='Unique')\n",
    "\n",
    "result = pd.merge(unique_razor, unique_counts, on=feature, how='left').fillna({'Unique': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptides_mappings = pd.Series(merged_mapping[feature].values, index=merged_mapping['Sequence']).to_dict()\n",
    "peptides_mapping_dict = {key: set(value.split(';')) for key, value in peptides_mappings.items()}\n",
    "\n",
    "razor_uniq_dict = pd.Series(result['Unique_razor'].values, index=result[feature]).to_dict()\n",
    "unique_genes = result[result['Unique'] > 0][feature].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_leading(features, more_then_half=False):\n",
    "    # Filter the counts for the genes in the set\n",
    "    relevant_counts = {feature: razor_uniq_dict[feature] for feature in features}\n",
    "    # Find the max count\n",
    "    max_count = max(relevant_counts.values())\n",
    "    \n",
    "    if more_then_half:\n",
    "        leading_genes = [feature for feature, count in relevant_counts.items() if count >= max_count / 2]\n",
    "    \n",
    "    else:\n",
    "        leading_genes = [feature for feature, count in relevant_counts.items() if count  == max_count]\n",
    "\n",
    "    return set(sorted(leading_genes))\n",
    "\n",
    "\n",
    "\n",
    "def build_peptide_gene_graph(peptides_mapping_dict):\n",
    "    \"\"\"\n",
    "    Build a graph where peptides and proteins are nodes.\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    for peptide, features in peptides_mapping_dict.items():\n",
    "        for feature in features:\n",
    "            G.add_node(peptide, type='peptide')\n",
    "            G.add_node(feature, type='feature')\n",
    "            G.add_edge(peptide, feature)\n",
    "    return G\n",
    "\n",
    "\n",
    "def sort_by_count(features_list):\n",
    "    if len(features_list) == 1:\n",
    "        return features_list\n",
    "    # sort by razor unique count, from biggest to smallest\n",
    "    return sorted(list(set(features_list)), key=lambda x: razor_uniq_dict[x], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = build_peptide_gene_graph(peptides_mapping_dict)\n",
    "connected_components = nx.connected_components(G)\n",
    "\n",
    "final_protein_groups = []\n",
    "\n",
    "for component in connected_components:\n",
    "    component_copy = set(component)  \n",
    "    features = [node for node in component_copy if G.nodes[node]['type'] == 'feature']\n",
    "    peptides = [node for node in component_copy if G.nodes[node]['type'] == 'peptide']\n",
    "    \n",
    "    # find proteins with max count\n",
    "    for feature in features:\n",
    "        \n",
    "        if len(peptides) == 0 or len(features) == 0:\n",
    "            print('Error')\n",
    "            print(f'Peptides: {peptides}')\n",
    "            print(f'Features: {features}')\n",
    "            raise ValueError('Peptides or features are not empty')\n",
    "       \n",
    "        leading = list(find_leading(features))\n",
    "        leading_unique = set(leading) & set(unique_genes)\n",
    "        if len(leading) > 1 and  len(leading_unique) > 0:\n",
    "            # if intersect with unique_genes - take the first unique gene\n",
    "            leading = list(leading_unique)[0]\n",
    "        else:\n",
    "            leading = leading[0]\n",
    "                \n",
    "        \n",
    "        # Get all peptides directly connected to the leading protein\n",
    "        leading_peptides = [peptide for peptide in peptides if G.has_edge(leading, peptide)]\n",
    "        # Find other proteins connected only to these leading peptides\n",
    "        other = set()\n",
    "\n",
    "        for peptide in leading_peptides:\n",
    "            connected_proteins = set(G.neighbors(peptide)) & set(features)  # Proteins connected to this peptide\n",
    "            \n",
    "            # Filter out proteins that are connected to peptides not in leading_peptides\n",
    "            valid_features = set()\n",
    "            for protein in connected_proteins:\n",
    "                protein_peptides = set(G.neighbors(protein)) & set(peptides)  # Peptides connected to this protein\n",
    "                if protein_peptides.issubset(set(leading_peptides)):\n",
    "                    valid_features.add(protein)\n",
    "\n",
    "            # Update 'other' with proteins that meet the criteria\n",
    "            other.update(valid_features)\n",
    "\n",
    "        other.discard(leading)\n",
    "        leading_group = list(other) + [leading]\n",
    "\n",
    "        razor_feature = find_leading(leading_group, more_then_half=False)\n",
    "        if len(razor_feature) > 1:\n",
    "            # keep only the first unique if there are more than one and unique is present\n",
    "            if len(razor_feature & set(unique_genes)) > 0:\n",
    "                razor_feature = sort_by_count(list(razor_feature & set(unique_genes)))[0]\n",
    "            else:\n",
    "                razor_feature = list(razor_feature)[0]\n",
    "        \n",
    "        final_protein_group = {\n",
    "            'features': sort_by_count(leading_group),\n",
    "            'peptides': sorted(list(set(leading_peptides))),\n",
    "            'razor_feature': list(razor_feature)[0],\n",
    "            'major_features': sort_by_count(list(find_leading(leading_group, more_then_half=True))),\n",
    "        }\n",
    "        \n",
    "        final_protein_groups.append(final_protein_group)\n",
    "            \n",
    "        # Remove the proteins and peptides from the component_copy\n",
    "        to_remove = set(leading_group) | set(leading_peptides)\n",
    "        component_copy -= to_remove\n",
    "        features = [feature for feature in features if feature not in set(leading_group)]\n",
    "        peptides = [peptide for peptide in peptides if peptide not in set(leading_peptides)]\n",
    "\n",
    "        if len(peptides) == 0 and len(features) == 0:\n",
    "            break\n",
    "    \n",
    "    if len(peptides) == 0 and len(features) == 0:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "629\n"
     ]
    }
   ],
   "source": [
    "protein_groups_as_strings = [';'.join(sorted(group['major_features'])) for group in final_protein_groups]\n",
    "print(len(protein_groups_as_strings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(629, 4)\n",
      "(7022, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>peptides</th>\n",
       "      <th>razor_feature</th>\n",
       "      <th>major_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P05154;G3V2M1;G3V264;G3V482;G3V265;G3V5I3;G3V4...</td>\n",
       "      <td>AAAATGTIFTFR</td>\n",
       "      <td>{P05154}</td>\n",
       "      <td>P05154;G3V2M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P05154;G3V2M1;G3V264;G3V482;G3V265;G3V5I3;G3V4...</td>\n",
       "      <td>AKWETSFNHK</td>\n",
       "      <td>{P05154}</td>\n",
       "      <td>P05154;G3V2M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P05154;G3V2M1;G3V264;G3V482;G3V265;G3V5I3;G3V4...</td>\n",
       "      <td>AVVEVDESGTR</td>\n",
       "      <td>{P05154}</td>\n",
       "      <td>P05154;G3V2M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P05154;G3V2M1;G3V264;G3V482;G3V265;G3V5I3;G3V4...</td>\n",
       "      <td>DFTFDLYR</td>\n",
       "      <td>{P05154}</td>\n",
       "      <td>P05154;G3V2M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P05154;G3V2M1;G3V264;G3V482;G3V265;G3V5I3;G3V4...</td>\n",
       "      <td>EDQYHYLLDR</td>\n",
       "      <td>{P05154}</td>\n",
       "      <td>P05154;G3V2M1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features      peptides  \\\n",
       "0  P05154;G3V2M1;G3V264;G3V482;G3V265;G3V5I3;G3V4...  AAAATGTIFTFR   \n",
       "0  P05154;G3V2M1;G3V264;G3V482;G3V265;G3V5I3;G3V4...    AKWETSFNHK   \n",
       "0  P05154;G3V2M1;G3V264;G3V482;G3V265;G3V5I3;G3V4...   AVVEVDESGTR   \n",
       "0  P05154;G3V2M1;G3V264;G3V482;G3V265;G3V5I3;G3V4...      DFTFDLYR   \n",
       "0  P05154;G3V2M1;G3V264;G3V482;G3V265;G3V5I3;G3V4...    EDQYHYLLDR   \n",
       "\n",
       "  razor_feature major_features  \n",
       "0      {P05154}  P05154;G3V2M1  \n",
       "0      {P05154}  P05154;G3V2M1  \n",
       "0      {P05154}  P05154;G3V2M1  \n",
       "0      {P05154}  P05154;G3V2M1  \n",
       "0      {P05154}  P05154;G3V2M1  "
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_protein_groups_df = pd.DataFrame(final_protein_groups)\n",
    "print(final_protein_groups_df.shape)\n",
    "\n",
    "# split peptides to different rows \n",
    "final_matching = final_protein_groups_df.explode('peptides')\n",
    "final_matching['major_features'] = final_matching['major_features'].apply(lambda x: ';'.join(x))\n",
    "final_matching['features'] = final_matching['features'].apply(lambda x: ';'.join(x))\n",
    "\n",
    "print(final_matching.shape)\n",
    "final_matching.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "for center in centers:\n",
    "    # write to file\n",
    "    final_matching.to_csv(f'{path_to_data}/{center}/mapping.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedprot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
