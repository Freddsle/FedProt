{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-May-24 18:40:59 - rpy2.situation - INFO - cffi mode is CFFI_MODE.ANY\n",
      "24-May-24 18:40:59 - rpy2.situation - DEBUG - Looking for R home with: R RHOME\n",
      "24-May-24 18:40:59 - rpy2.situation - INFO - R home found: /home/yuliya/anaconda3/envs/fedprot/lib/R\n",
      "24-May-24 18:40:59 - rpy2.situation - DEBUG - Looking for LD_LIBRARY_PATH with: /home/yuliya/anaconda3/envs/fedprot/lib/R/bin/Rscript -e cat(Sys.getenv(\"LD_LIBRARY_PATH\"))\n",
      "24-May-24 18:41:00 - rpy2.situation - INFO - R library path: \n",
      "24-May-24 18:41:00 - rpy2.situation - INFO - LD_LIBRARY_PATH: \n",
      "24-May-24 18:41:00 - rpy2.rinterface_lib.ffi_proxy - DEBUG - cffi mode is InterfaceType.API\n",
      "24-May-24 18:41:00 - rpy2.rinterface_lib.embedded - INFO - Default options to initialize R: rpy2, --quiet, --no-save\n",
      "24-Mai-24 18:41:00 - rpy2.rinterface_lib.embedded - INFO - R is already initialized. No need to initialize.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "sys.path.append('/home/yuliya/repos/cosybio/FedProt/FedProt')\n",
    "from client import Client\n",
    "import utils\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\", datefmt=\"%d-%b-%y %H:%M:%S\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/yuliya/repos/cosybio/FedProt/data/TMT_data/\"\n",
    "MODE = \"01_smaller_lib_balanced_PG_MajorPG\"\n",
    "cohorts = [\"Center1\", \"Center2\", \"Center3\"]\n",
    "output_path = \"/home/yuliya/repos/cosybio/FedProt/evaluation/TMT_data/\"\n",
    "\n",
    "\n",
    "data_dir = f\"{data_dir}/{MODE}\"  # path to data folder\n",
    "output_path = f\"{output_path}/{MODE}/results\"  # path to output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"/home/yuliya/repos/cosybio/random_tests_scripts/2024_05_Added_zero_features_FedProt/\"\n",
    "# MODE = \"data\"\n",
    "# cohorts = [\"Center1\", \"Center2\"]#, \"Center3\"]\n",
    "# output_path = \"/home/yuliya/repos/cosybio/random_tests_scripts/2024_05_Added_zero_features_FedProt/\"\n",
    "\n",
    "\n",
    "# data_dir = f\"{data_dir}/{MODE}\"  # path to data folder\n",
    "# output_path = f\"{output_path}/{MODE}/results\"  # path to output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "0.8 False TMT\n",
      "True True True True\n",
      "['heathy', 'FSGS'] []\n"
     ]
    }
   ],
   "source": [
    "with open(f\"{data_dir}/{cohorts[0]}/config.yml\", 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# parse config\n",
    "intensity_path = config[\"fedprot\"][\"intensities\"]\n",
    "design_path = config[\"fedprot\"][\"design\"]\n",
    "use_counts = config[\"fedprot\"][\"use_counts\"]\n",
    "\n",
    "if use_counts:\n",
    "    counts_path = config[\"fedprot\"][\"counts\"]\n",
    "else:\n",
    "    counts_path = None\n",
    "result_name = config[\"fedprot\"][\"result_table\"]\n",
    "\n",
    "max_na_rate = config[\"fedprot\"][\"max_na_rate\"]\n",
    "log_transformed = config[\"fedprot\"][\"log_transformed\"]\n",
    "\n",
    "experiment_type = config[\"fedprot\"][\"experiment_type\"]\n",
    "\n",
    "if experiment_type == \"TMT\":\n",
    "    ref_type = config[\"fedprot\"][\"ref_type\"]\n",
    "    plex_covariate = config[\"fedprot\"][\"plex_covariate\"]\n",
    "    plex_column = config[\"fedprot\"][\"plex_column\"]\n",
    "\n",
    "    use_median = config[\"fedprot\"][\"use_median\"]\n",
    "    use_irs = config[\"fedprot\"][\"use_irs\"]\n",
    "\n",
    "remove_single_pep_protein = config[\"fedprot\"][\"remove_single_pep_protein\"]\n",
    "target_classes = config[\"fedprot\"][\"target_classes\"]\n",
    "covariates = config[\"fedprot\"][\"covariates\"]\n",
    "\n",
    "only_shared_proteins = config[\"fedprot\"][\"only_shared_proteins\"]\n",
    "\n",
    "print(\"Loading data\")\n",
    "# print config  \n",
    "print(max_na_rate, log_transformed, experiment_type)\n",
    "print(plex_covariate, use_median, use_irs, remove_single_pep_protein)\n",
    "print(target_classes, covariates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Mai-24 18:41:00 - root - INFO - Client Center1: Using counts.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1: Using TMT-plex column 'Pool'.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1: Checking TMT-plex Pool1 for single non-NA values.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1: Checking TMT-plex Pool2 for single non-NA values.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1: Found 2 TMT-plexes. Plexes: ['Pool1', 'Pool2']\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1: TMT data loaded successfully.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1: Replacing rows with only one non-NA value with NA.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1: Rows will be affected : 0\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1: TMT data will be log2 transformed after normalization.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1: Samples are filtered based on target classes.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1: 20 samples are kept.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1: Loaded 20 samples and 490 proteins.\n",
      "24-Mai-24 18:41:00 - root - INFO - Min counts have been computed...\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2: Using counts.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2: Using TMT-plex column 'Pool'.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2: Checking TMT-plex Pool5 for single non-NA values.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2: Checking TMT-plex Pool3 for single non-NA values.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2: Found 2 TMT-plexes. Plexes: ['Pool3', 'Pool5']\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2: TMT data loaded successfully.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2: Replacing rows with only one non-NA value with NA.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2: Rows will be affected : 0\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2: TMT data will be log2 transformed after normalization.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2: Samples are filtered based on target classes.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2: 19 samples are kept.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2: Loaded 19 samples and 508 proteins.\n",
      "24-Mai-24 18:41:00 - root - INFO - Min counts have been computed...\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3: Using counts.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3: Using TMT-plex column 'Pool'.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3: Checking TMT-plex Pool4 for single non-NA values.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3: Checking TMT-plex Pool6 for single non-NA values.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3: Found 2 TMT-plexes. Plexes: ['Pool4', 'Pool6']\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3: TMT data loaded successfully.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3: Replacing rows with only one non-NA value with NA.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3: Rows will be affected : 0\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3: TMT data will be log2 transformed after normalization.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3: Samples are filtered based on target classes.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3: 20 samples are kept.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3: Loaded 20 samples and 425 proteins.\n",
      "24-Mai-24 18:41:00 - root - INFO - Min counts have been computed...\n",
      "24-Mai-24 18:41:00 - root - INFO - Plexes: ['Pool1', 'Pool2', 'Pool3', 'Pool5', 'Pool4', 'Pool6']\n"
     ]
    }
   ],
   "source": [
    "store_clients = {}\n",
    "\n",
    "prot_names = []\n",
    "if experiment_type == \"TMT\":\n",
    "    if plex_covariate:\n",
    "        plex_covariates_list = []\n",
    "\n",
    "if use_counts:\n",
    "    list_of_counts = []\n",
    "\n",
    "# clinets are joining\n",
    "for cohort_name in cohorts:\n",
    "    intensity_file_path = f\"{data_dir}/{cohort_name}/{intensity_path}\"\n",
    "    design_file_path = f\"{data_dir}/{cohort_name}/{design_path}\"\n",
    "\n",
    "    if use_counts:\n",
    "        count_file_path = f\"{data_dir}/{cohort_name}/{counts_path}\"\n",
    "    else:\n",
    "        count_file_path = None\n",
    "    \n",
    "    # Initialize the client\n",
    "    client = Client(\n",
    "        cohort_name,\n",
    "        intensity_file_path,\n",
    "        count_file_path,\n",
    "        design_file_path,\n",
    "        experiment_type,\n",
    "        log_transformed = log_transformed,\n",
    "        ref_type = ref_type,\n",
    "        plex_column = plex_column,\n",
    "        target_classes = target_classes,\n",
    "    )\n",
    "    store_clients[client.cohort_name] = client\n",
    "\n",
    "    if experiment_type == \"TMT\":\n",
    "        if plex_covariate:\n",
    "            plex_covariates_list += client.tmt_names\n",
    "\n",
    "    if use_counts:\n",
    "        min_counts = client.get_min_count()\n",
    "        list_of_counts.append(min_counts.to_dict())\n",
    "        logging.info(\"Min counts have been computed...\")\n",
    "\n",
    "    # add list (as list of lists) of protein names\n",
    "    prot_names.append(client.prot_names)\n",
    "\n",
    "logging.info(f\"Plexes: {plex_covariates_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Mai-24 18:41:00 - root - INFO - SERVER: Common proteins: 621\n",
      "24-Mai-24 18:41:00 - root - INFO - Min counts have been aggregated..., shape: (621,)\n"
     ]
    }
   ],
   "source": [
    "# SERVER SIDE\n",
    "prot_names = utils.get_analyzed_proteins(prot_names, only_shared_proteins)\n",
    "logging.info(f\"SERVER: Common proteins: {len(prot_names)}\")\n",
    "\n",
    "variables = target_classes + covariates\n",
    "\n",
    "if use_counts:\n",
    "    min_counts = list()\n",
    "    for local_counts in list_of_counts:\n",
    "        min_counts.append(pd.DataFrame.from_dict(local_counts, orient='index'))\n",
    "    global_min_counts = pd.concat(min_counts, axis=1)\n",
    "    global_min_counts = global_min_counts.min(axis=1)\n",
    "    global_min_counts = global_min_counts.reindex(prot_names, fill_value=0)\n",
    "    logging.info(\"Min counts have been aggregated..., shape: \" + str(global_min_counts.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Mai-24 18:41:00 - root - INFO - Client Center1:\tSome protein groups are not in the client list: 131 and will be added.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1:\tProtein groups are validated.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1:\t3 columns are excluded from the design matrix: {'CommonReference', 'Pool', 'Center'}\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1:\tValidated 20 samples and 621 proteins.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1:\tAdding cohort effects to the design matrix.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1:\tAdding TMT-plex as a covariate.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1:\tCollinearity will be checked.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1:\tCohort effects are added to the design matrix.\n",
      "24-Mai-24 18:41:00 - root - INFO - Samples in Center1 data: 20\n",
      "24-Mai-24 18:41:00 - root - INFO - Protein groups in Center1 data:  621\n",
      "24-Mai-24 18:41:00 - root - INFO - Design Center1 has beed updated with cohort effects\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1:\tProtein groups: 621\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1:\tProtein groups supported by a single peptide will be excluded.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1:\tProtein groups after filter: 580\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1:\tProtein groups detected in less than 0.8 of each target class will be excluded.\n",
      "24-Mai-24 18:41:00 - root - INFO - \n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2:\tSome protein groups are not in the client list: 113 and will be added.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2:\tProtein groups are validated.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2:\t3 columns are excluded from the design matrix: {'CommonReference', 'Pool', 'Center'}\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2:\tValidated 19 samples and 621 proteins.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2:\tAdding cohort effects to the design matrix.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2:\tAdding TMT-plex as a covariate.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2:\tCohort effects are added to the design matrix.\n",
      "24-Mai-24 18:41:00 - root - INFO - Samples in Center2 data: 19\n",
      "24-Mai-24 18:41:00 - root - INFO - Protein groups in Center2 data:  621\n",
      "24-Mai-24 18:41:00 - root - INFO - Design Center2 has beed updated with cohort effects\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2:\tProtein groups: 621\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2:\tProtein groups supported by a single peptide will be excluded.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2:\tProtein groups after filter: 580\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2:\tProtein groups detected in less than 0.8 of each target class will be excluded.\n",
      "24-Mai-24 18:41:00 - root - INFO - \n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3:\tSome protein groups are not in the client list: 196 and will be added.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3:\tProtein groups are validated.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3:\t3 columns are excluded from the design matrix: {'CommonReference', 'Pool', 'Center'}\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3:\tValidated 20 samples and 621 proteins.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3:\tAdding cohort effects to the design matrix.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3:\tAdding TMT-plex as a covariate.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3:\tCohort effects are added to the design matrix.\n",
      "24-Mai-24 18:41:00 - root - INFO - Samples in Center3 data: 20\n",
      "24-Mai-24 18:41:00 - root - INFO - Protein groups in Center3 data:  621\n",
      "24-Mai-24 18:41:00 - root - INFO - Design Center3 has beed updated with cohort effects\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3:\tProtein groups: 621\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3:\tProtein groups supported by a single peptide will be excluded.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3:\tProtein groups after filter: 580\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3:\tProtein groups detected in less than 0.8 of each target class will be excluded.\n",
      "24-Mai-24 18:41:00 - root - INFO - \n",
      "24-Mai-24 18:41:00 - root - INFO - CLIENT: Filters have been applied...\n"
     ]
    }
   ],
   "source": [
    "# CLIENT SIDE\n",
    "# validate inputs and add cohort effects\n",
    "# apply filters\n",
    "\n",
    "list_of_na_counts_tuples = []\n",
    "total_samples = {}\n",
    "\n",
    "for c in cohorts:\n",
    "    client = store_clients[c]\n",
    "\n",
    "    if use_counts:\n",
    "        client.counts = global_min_counts.copy()\n",
    "    client.validate_inputs(prot_names, variables)\n",
    "\n",
    "    # add cohort effect columns to each design matrix\n",
    "    # if plex_covariate exists, use this column as a cohort effect\n",
    "    if plex_covariate:\n",
    "        client.add_cohort_effects_to_design(plex_covariates_list, plex_covariate)\n",
    "    else:\n",
    "        client.add_cohort_effects_to_design(cohorts)\n",
    "\n",
    "    logging.info(f\"Samples in {client.cohort_name} data: {len(client.sample_names)}\")        \n",
    "    logging.info(f\"Protein groups in {client.cohort_name} data:  {len(client.prot_names)}\")\n",
    "    logging.info(f\"Design {client.cohort_name} has beed updated with cohort effects\")\n",
    "\n",
    "    na_count_in_variable, samples_per_class = client.apply_filters(\n",
    "            min_f=max_na_rate, \n",
    "            remove_single_peptide_prots=remove_single_pep_protein\n",
    "        )\n",
    "    # add each value from a dict to a list\n",
    "    total_samples[c] = sum(samples_per_class.values())\n",
    "    # add both as a tuple to the list\n",
    "    list_of_na_counts_tuples.append((\n",
    "        na_count_in_variable.to_dict(orient='index'), samples_per_class))\n",
    "    logging.info(\"\")\n",
    "    \n",
    "logging.info(\"CLIENT: Filters have been applied...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Mai-24 18:41:00 - root - INFO - SERVER: Proteins after filtering: 532\n"
     ]
    }
   ],
   "source": [
    "# SERVER SIDE\n",
    "keep_proteins = utils.filter_features_na_rate(list_of_na_counts_tuples, max_na_rate)\n",
    "logging.info(f\"SERVER: Proteins after filtering: {len(keep_proteins)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Mai-24 18:41:00 - root - INFO - Samples in Center1 data: 20, protein groups: 532\n",
      "24-Mai-24 18:41:00 - root - INFO - Samples in Center2 data: 19, protein groups: 532\n",
      "24-Mai-24 18:41:00 - root - INFO - Samples in Center3 data: 20, protein groups: 532\n"
     ]
    }
   ],
   "source": [
    "for c in cohorts:\n",
    "    client = store_clients[c]\n",
    "    client.update_prot_names(keep_proteins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if TMT and use_median, compute medians\n",
    "# if experiment_type == \"TMT\" and use_median:\n",
    "    \n",
    "#     # server nows about total_samples \n",
    "#     avg_medians = []\n",
    "\n",
    "#     for c in cohorts:\n",
    "#         client = store_clients[c]\n",
    "#         avg_medians.append(client.compute_medians())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if TMT and use_median, compute medians\n",
    "# if experiment_type == \"TMT\" and use_median:\n",
    "#     global_median_mean = utils.aggregate_medians(avg_medians, total_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if TMT and use_median, compute medians\n",
    "# if experiment_type == \"TMT\" and use_median:\n",
    "#     for c in cohorts:\n",
    "#         client = store_clients[c]\n",
    "#         client.mean_median_centering(global_median_mean)\n",
    "\n",
    "#         # proceed with IRS normalization\n",
    "#         if experiment_type == \"TMT\" and use_irs:\n",
    "#             client.irsNorm_in_silico_single_center()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LmFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Mai-24 18:41:00 - root - INFO - Client Center1:\tPlex column is removed from the design matrix.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1:\tLog2(x+1) transformed intensities.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center1:\tPrepared for limma. Samples: 20, Proteins: 532.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2:\tPlex column is removed from the design matrix.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2:\tLog2(x+1) transformed intensities.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2:\tPrepared for limma. Samples: 19, Proteins: 532.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3:\tPlex column is removed from the design matrix.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3:\tLog2(x+1) transformed intensities.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3:\tPrepared for limma. Samples: 20, Proteins: 532.\n"
     ]
    }
   ],
   "source": [
    "for c in cohorts:\n",
    "    client = store_clients[c]\n",
    "    client.prepare_for_limma(keep_proteins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_list = []\n",
    "\n",
    "for c in cohorts:\n",
    "    client = store_clients[c]\n",
    "    masks_list.append(client.get_mask())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Mai-24 18:41:00 - root - INFO - SERVER: Number of proteins: 532, number of variables: 7\n",
      "24-Mai-24 18:41:00 - root - INFO - SMPC is not used, aggregating masks\n"
     ]
    }
   ],
   "source": [
    "variables = client.design.columns.values\n",
    "\n",
    "# SERVER SIDE\n",
    "k = len(variables)\n",
    "n = len(keep_proteins)\n",
    "logging.info(f\"SERVER: Number of proteins: {n}, number of variables: {k}\")\n",
    "\n",
    "# aggregate mask\n",
    "global_mask = utils.aggregate_masks(masks_list, n, k, used_SMPC=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Mai-24 18:41:00 - root - INFO - Client Center1:\tCollinearity check and update completed.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center2:\tCollinearity check and update completed.\n",
      "24-Mai-24 18:41:00 - root - INFO - Client Center3:\tCollinearity check and update completed.\n"
     ]
    }
   ],
   "source": [
    "list_of_masks = []\n",
    "\n",
    "for c in cohorts:\n",
    "    client = store_clients[c]\n",
    "    updated_masks = client.updated_mask(global_mask)\n",
    "    list_of_masks.append(updated_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Mai-24 18:41:00 - root - INFO - SMPC is not used, aggregating masks\n"
     ]
    }
   ],
   "source": [
    "mask_glob = utils.aggregate_masks(list_of_masks, n, k, second_round=True, used_SMPC=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Mai-24 18:41:00 - root - INFO - Start computing XtX and XtY\n",
      "24-Mai-24 18:41:00 - root - INFO - XtX and XtY have been computed for Center1\n",
      "24-Mai-24 18:41:00 - root - INFO - Design colnames: ['heathy' 'FSGS' 'Pool2' 'Pool3' 'Pool5' 'Pool4' 'Pool6']\n",
      "24-Mai-24 18:41:00 - root - INFO - Start computing XtX and XtY\n",
      "24-Mai-24 18:41:00 - root - INFO - XtX and XtY have been computed for Center2\n",
      "24-Mai-24 18:41:00 - root - INFO - Design colnames: ['heathy' 'FSGS' 'Pool2' 'Pool3' 'Pool5' 'Pool4' 'Pool6']\n",
      "24-Mai-24 18:41:00 - root - INFO - Start computing XtX and XtY\n",
      "24-Mai-24 18:41:00 - root - INFO - XtX and XtY have been computed for Center3\n",
      "24-Mai-24 18:41:00 - root - INFO - Design colnames: ['heathy' 'FSGS' 'Pool2' 'Pool3' 'Pool5' 'Pool4' 'Pool6']\n"
     ]
    }
   ],
   "source": [
    "# CLIENT SIDE\n",
    "XtX_XtY_list = []\n",
    "\n",
    "for c in cohorts:\n",
    "    client = store_clients[c]\n",
    "    logging.info(\"Start computing XtX and XtY\")\n",
    "    XtX, XtY = client.compute_XtX_XtY()\n",
    "    XtX_XtY_list.append((XtX, XtY))\n",
    "\n",
    "    logging.info(f\"XtX and XtY have been computed for {client.cohort_name}\")\n",
    "    logging.info(f'Design colnames: {client.design.columns.values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Mai-24 18:40:06 - root - INFO - SMPC is not used, aggregating XtX and XtY\n",
      "24-Mai-24 18:40:06 - root - INFO - SERVER: XtX and XtY have been aggregated\n"
     ]
    }
   ],
   "source": [
    "# SERVER SIDE\n",
    "XtX_glob, XtY_glob = utils.aggregate_XtX_XtY(XtX_XtY_list, n, k, used_SMPC=False)\n",
    "logging.info(\"SERVER: XtX and XtY have been aggregated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Mai-24 18:40:06 - root - INFO - SERVER: Computing beta and stdev\n",
      "24-Mai-24 18:40:06 - root - INFO - Detected partial NA coefficients for 208 probe(s).\n"
     ]
    }
   ],
   "source": [
    "logging.info('SERVER: Computing beta and stdev')\n",
    "beta, stdev_unscaled = utils.compute_beta_and_stdev(XtX_glob, XtY_glob, n, k, mask_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Mai-24 18:40:06 - root - INFO - Start computation of SSE and cov_coef...\n",
      "24-Mai-24 18:40:06 - root - INFO - SSE and cov_coef have been computed for Center1\n",
      "24-Mai-24 18:40:06 - root - INFO - Start computation of SSE and cov_coef...\n",
      "24-Mai-24 18:40:06 - root - INFO - SSE and cov_coef have been computed for Center2\n",
      "24-Mai-24 18:40:06 - root - INFO - Start computation of SSE and cov_coef...\n",
      "24-Mai-24 18:40:06 - root - INFO - SSE and cov_coef have been computed for Center3\n"
     ]
    }
   ],
   "source": [
    "# CLIENT SIDE\n",
    "list_of_sse_cov_coef = []\n",
    "\n",
    "for c in cohorts:\n",
    "    client = store_clients[c]\n",
    "    logging.info(f\"Start computation of SSE and cov_coef...\")\n",
    "    SSE, cov_coef = client.compute_SSE_and_cov_coef(beta, mask_glob)\n",
    "    intensities_sum = np.array(client.sum_intensities())\n",
    "    n_measurements = np.array(client.get_not_na())\n",
    "    list_of_sse_cov_coef.append((SSE, cov_coef, intensities_sum, n_measurements))\n",
    "    logging.info(f\"SSE and cov_coef have been computed for {client.cohort_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Mai-24 18:40:06 - root - INFO - SERVER: Aggregating SSE and cov_coef...\n"
     ]
    }
   ],
   "source": [
    "# SERVER SIDE\n",
    "logging.info(\"SERVER: Aggregating SSE and cov_coef...\")\n",
    "SSE, cov_coef, Amean, n_measurements = utils.aggregate_SSE_and_cov_coef(\n",
    "        list_of_sse_cov_coef, n, k, False, len(store_clients))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Mai-24 18:40:06 - root - INFO - SERVER: Aggregating SSE and cov_coef...\n",
      "24-Mai-24 18:40:06 - root - INFO - Aggregation of SSE is done, start computing global parameters...\n"
     ]
    }
   ],
   "source": [
    "# SERVER SIDE\n",
    "logging.info(\"SERVER: Aggregating SSE and cov_coef...\")\n",
    "SSE, cov_coef, Amean, n_measurements = utils.aggregate_SSE_and_cov_coef(\n",
    "        list_of_sse_cov_coef, n, k, False, len(store_clients))\n",
    "\n",
    "logging.info('Aggregation of SSE is done, start computing global parameters...')\n",
    "sigma, cov_coef, df_residual, Amean, var = utils.compute_SSE_and_cov_coef_global(\n",
    "            cov_coef, SSE, Amean, n_measurements, n, mask_glob\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Mai-24 18:40:06 - root - INFO - Making contrasts...\n",
      "24-Mai-24 18:40:06 - root - INFO - Fit contrasts...\n",
      "24-Mai-24 18:40:06 - root - INFO - .... orthogonality of design matrix is False\n"
     ]
    }
   ],
   "source": [
    "logging.info('Making contrasts...')\n",
    "contrasts = utils.make_contrasts(target_classes, variables)\n",
    "\n",
    "logging.info('Fit contrasts...')\n",
    "contrast_matrix = contrasts.values\n",
    "ncoef = cov_coef.shape[1]\n",
    "\n",
    "beta, stdev_unscaled, cov_coef = utils.fit_contrasts(\n",
    "    beta, \n",
    "    contrast_matrix,\n",
    "    cov_coef, \n",
    "    ncoef, \n",
    "    stdev_unscaled\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eBays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Mai-24 18:40:06 - root - INFO - Start eBays stage...\n",
      "24-Mai-24 18:40:06 - root - INFO - \"Result table is pre-computed...\n"
     ]
    }
   ],
   "source": [
    "logging.info('Start eBays stage...')\n",
    "results, df_total = utils.moderatedT(\n",
    "    var, \n",
    "    df_residual,\n",
    "    beta, \n",
    "    stdev_unscaled\n",
    ")\n",
    "results[\"AveExpr\"] = Amean\n",
    "logging.info('\"Result table is pre-computed...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Mai-24 18:40:06 - root - INFO - Computing B statistic...\n",
      "24-Mai-24 18:40:06 - root - INFO - Calculating tail p-values\n",
      "24-Mai-24 18:40:06 - root - INFO - B statistic has been computed...\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Computing B statistic...\")\n",
    "results = utils.Bstat(\n",
    "    df_total, \n",
    "    stdev_unscaled, \n",
    "    results,\n",
    "    stdev_coef_lim=np.array([0.1, 4]), proportion=0.01)\n",
    "logging.info(\"B statistic has been computed...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Mai-24 18:40:06 - root - INFO - Computing p-values...\n",
      "24-Mai-24 18:40:06 - root - INFO - P-values have been computed...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logging.info(\"Computing p-values...\")\n",
    "results = utils.topTableT( \n",
    "    results,\n",
    "    keep_proteins, \n",
    "    beta, \n",
    "    stdev_unscaled, \n",
    "    df_total,\n",
    "    adjust=\"fdr_bh\", p_value=1.0, lfc=0, confint=0.95)\n",
    "logging.info(\"P-values have been computed...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>AveExpr</th>\n",
       "      <th>B</th>\n",
       "      <th>logFC</th>\n",
       "      <th>CI.L</th>\n",
       "      <th>CI.R</th>\n",
       "      <th>adj.P.Val</th>\n",
       "      <th>P.Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A0A075B6H9</th>\n",
       "      <td>2.210671</td>\n",
       "      <td>14.685669</td>\n",
       "      <td>-4.521451</td>\n",
       "      <td>0.228686</td>\n",
       "      <td>0.019159</td>\n",
       "      <td>0.438213</td>\n",
       "      <td>0.061827</td>\n",
       "      <td>0.033252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A075B6I0</th>\n",
       "      <td>0.681843</td>\n",
       "      <td>13.010482</td>\n",
       "      <td>-6.526756</td>\n",
       "      <td>0.141067</td>\n",
       "      <td>-0.289957</td>\n",
       "      <td>0.572091</td>\n",
       "      <td>0.608181</td>\n",
       "      <td>0.503007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A075B6I9;P04211</th>\n",
       "      <td>3.592355</td>\n",
       "      <td>15.193368</td>\n",
       "      <td>-1.049331</td>\n",
       "      <td>0.382801</td>\n",
       "      <td>0.169285</td>\n",
       "      <td>0.596317</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.000696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A075B6K0;P01717;P01718</th>\n",
       "      <td>-1.451562</td>\n",
       "      <td>13.128078</td>\n",
       "      <td>-5.718139</td>\n",
       "      <td>-0.145901</td>\n",
       "      <td>-0.355983</td>\n",
       "      <td>0.064182</td>\n",
       "      <td>0.236383</td>\n",
       "      <td>0.162603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A075B6K2;A0A075B6K5;P80748</th>\n",
       "      <td>-1.199579</td>\n",
       "      <td>14.536304</td>\n",
       "      <td>-6.045198</td>\n",
       "      <td>-0.180040</td>\n",
       "      <td>-0.492721</td>\n",
       "      <td>0.132641</td>\n",
       "      <td>0.335490</td>\n",
       "      <td>0.244050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q9Y520</th>\n",
       "      <td>-2.685680</td>\n",
       "      <td>12.909182</td>\n",
       "      <td>-3.580968</td>\n",
       "      <td>-0.403983</td>\n",
       "      <td>-0.718379</td>\n",
       "      <td>-0.089587</td>\n",
       "      <td>0.030170</td>\n",
       "      <td>0.014461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q9Y5C1</th>\n",
       "      <td>-4.562580</td>\n",
       "      <td>15.125914</td>\n",
       "      <td>2.000507</td>\n",
       "      <td>-0.438139</td>\n",
       "      <td>-0.630553</td>\n",
       "      <td>-0.245724</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q9Y5Y7</th>\n",
       "      <td>-3.533014</td>\n",
       "      <td>17.408097</td>\n",
       "      <td>-1.222250</td>\n",
       "      <td>-0.305987</td>\n",
       "      <td>-0.479525</td>\n",
       "      <td>-0.132449</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>0.000837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q9Y6R7</th>\n",
       "      <td>-5.208972</td>\n",
       "      <td>19.885664</td>\n",
       "      <td>4.213034</td>\n",
       "      <td>-0.314997</td>\n",
       "      <td>-0.436166</td>\n",
       "      <td>-0.193828</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q9Y6Z7</th>\n",
       "      <td>-1.530767</td>\n",
       "      <td>16.075000</td>\n",
       "      <td>-5.731494</td>\n",
       "      <td>-0.071480</td>\n",
       "      <td>-0.165045</td>\n",
       "      <td>0.022085</td>\n",
       "      <td>0.198208</td>\n",
       "      <td>0.131518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>532 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     t    AveExpr         B     logFC  \\\n",
       "A0A075B6H9                    2.210671  14.685669 -4.521451  0.228686   \n",
       "A0A075B6I0                    0.681843  13.010482 -6.526756  0.141067   \n",
       "A0A075B6I9;P04211             3.592355  15.193368 -1.049331  0.382801   \n",
       "A0A075B6K0;P01717;P01718     -1.451562  13.128078 -5.718139 -0.145901   \n",
       "A0A075B6K2;A0A075B6K5;P80748 -1.199579  14.536304 -6.045198 -0.180040   \n",
       "...                                ...        ...       ...       ...   \n",
       "Q9Y520                       -2.685680  12.909182 -3.580968 -0.403983   \n",
       "Q9Y5C1                       -4.562580  15.125914  2.000507 -0.438139   \n",
       "Q9Y5Y7                       -3.533014  17.408097 -1.222250 -0.305987   \n",
       "Q9Y6R7                       -5.208972  19.885664  4.213034 -0.314997   \n",
       "Q9Y6Z7                       -1.530767  16.075000 -5.731494 -0.071480   \n",
       "\n",
       "                                  CI.L      CI.R  adj.P.Val   P.Value  \n",
       "A0A075B6H9                    0.019159  0.438213   0.061827  0.033252  \n",
       "A0A075B6I0                   -0.289957  0.572091   0.608181  0.503007  \n",
       "A0A075B6I9;P04211             0.169285  0.596317   0.002470  0.000696  \n",
       "A0A075B6K0;P01717;P01718     -0.355983  0.064182   0.236383  0.162603  \n",
       "A0A075B6K2;A0A075B6K5;P80748 -0.492721  0.132641   0.335490  0.244050  \n",
       "...                                ...       ...        ...       ...  \n",
       "Q9Y520                       -0.718379 -0.089587   0.030170  0.014461  \n",
       "Q9Y5C1                       -0.630553 -0.245724   0.000158  0.000028  \n",
       "Q9Y5Y7                       -0.479525 -0.132449   0.002783  0.000837  \n",
       "Q9Y6R7                       -0.436166 -0.193828   0.000028  0.000003  \n",
       "Q9Y6Z7                       -0.165045  0.022085   0.198208  0.131518  \n",
       "\n",
       "[532 rows x 8 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not using counts - stop here and save the results\n",
    "if not use_counts:\n",
    "    logging.info(\"Writing results to file...\")\n",
    "    logging.info(\"File: \" + f\"{output_path}/{result_name}\")\n",
    "    output_file = f\"{output_path}/{result_name}\"\n",
    "    # results.to_csv(output_file, sep=\"\\t\")\n",
    "    logging.info(f\"Results have been saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Mai-24 10:56:06 - root - INFO - Size of global min counts: (350,)\n",
      "24-Mai-24 10:56:06 - root - INFO - Start spectral count eBayes stage...\n",
      "24-Mai-24 10:56:06 - root - INFO - Fitting LOWESS curve...\n",
      "24-Mai-24 10:56:06 - root - INFO - min_count: (350,), log_var: (350,)\n",
      "24-Mai-24 10:56:06 - root - INFO - Spectral count eBayes stage is done...\n"
     ]
    }
   ],
   "source": [
    "# SERVER SIDE\n",
    "if use_counts:\n",
    "    global_min_counts = global_min_counts[keep_proteins] + 1\n",
    "    logging.info(f\"Size of global min counts: {global_min_counts.shape}\")\n",
    "\n",
    "    logging.info(\"Start spectral count eBayes stage...\")\n",
    "    results = utils.spectral_count_ebayes(\n",
    "        results, \n",
    "        global_min_counts, \n",
    "        keep_proteins,\n",
    "        beta, \n",
    "        stdev_unscaled,\n",
    "        df_residual, \n",
    "        sigma,\n",
    "        return_sorted=False, fit_method=\"loess\")\n",
    "    logging.info(\"Spectral count eBayes stage is done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Mai-24 10:56:06 - root - INFO - Writing results...\n",
      "24-Mai-24 10:56:06 - root - INFO - Results have been saved to /home/yuliya/repos/cosybio/FedProt/evaluation/TMT_data//01_smaller_lib_balanced_PG_MajorPG/results/DPE.csv\n"
     ]
    }
   ],
   "source": [
    "# SERVER SIDE\n",
    "if use_counts:\n",
    "    logging.info(\"Writing results...\")\n",
    "    output_file = f\"{output_path}/{result_name}\"\n",
    "    results.to_csv(output_file, sep=\"\\t\")\n",
    "    logging.info(f\"Results have been saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedprot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
